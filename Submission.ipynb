{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>near_bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>near_bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>near_bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>near_bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>near_bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        near_bay  \n",
       "1      2401.0      1138.0         8.3014            358500.0        near_bay  \n",
       "2       496.0       177.0         7.2574            352100.0        near_bay  \n",
       "3       558.0       219.0         5.6431            341300.0        near_bay  \n",
       "4       565.0       259.0         3.8462            342200.0        near_bay  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Godwin/Documents/Workflow/ML Zoomcamp/Classification/Califonia Housing Data/housing.csv')\n",
    "\n",
    "#Formatting the column names to lower case and replacing empty spaces with '_'\n",
    "data.columns = data.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "#Formatting the strings in the data to lower case and replacing empty spaces with '_'\n",
    "categorical_col = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
    "for col in categorical_col:\n",
    "    data[col] = data[col].str.replace(' ', '_').str.lower()\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values with 0\n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "#Feature Engineering\n",
    "data['rooms_per_household'] = data['total_rooms']/ data['households']\n",
    "data['bedrooms_per_room'] = data['total_bedrooms']/data['total_rooms']\n",
    "data['population_per_household'] = data['population']/ data['households']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<1h_ocean'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mode for the 'ocean_proximity' column in the data\n",
    "data['ocean_proximity'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "households  total_bedrooms    0.966507\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column Correlation\n",
    "corr = data.corr()\n",
    "\n",
    "#Remocing self correlation and duplicate correlation\n",
    "upper_triangle = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "unique = upper_triangle.unstack().dropna()\n",
    "\n",
    "#Returning columns with the maximum correlation\n",
    "#unique.sort_values(ascending = False)\n",
    "\n",
    "max_corr_value = unique.max()\n",
    "unique[unique == max_corr_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = data['median_house_value'].mean()\n",
    "new_df = data.copy()\n",
    "new_df['above_average'] = (data['median_house_value'] > mean_value).astype('int')\n",
    "del new_df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = new_df.columns.tolist()\n",
    "new_df = new_df[columns]\n",
    "\n",
    "train_df, test_df = train_test_split(new_df, test_size = 0.2, random_state = 42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chacking the mutual information between the target variable and the categorical variables\n",
    "round(mutual_info_score(new_df['above_average'], new_df['ocean_proximity']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "train_df, test_df = train_test_split(new_df, test_size = 0.2, random_state = 42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.25, random_state = 42)\n",
    "\n",
    "y_train = train_df.pop('above_average')\n",
    "y_test = test_df.pop('above_average')\n",
    "y_val = val_df.pop('above_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = train_df.dtypes[train_df.dtypes == 'object'].index.to_list()\n",
    "numerical_col = train_df.dtypes[train_df.dtypes != 'object'].index.to_list()\n",
    "\n",
    "#Vetorizing data\n",
    "dv = DictVectorizer(sparse = False)\n",
    "dv.fit(train_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "names = dv.get_feature_names()\n",
    "\n",
    "X_train = dv.transform(train_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "X_test = dv.transform(test_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "X_val = dv.transform(val_df[numerical_col + categorical_col].to_dict(orient = 'records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Model Accuracy\n",
    "prediction = model.predict_proba(X_val)[:, 1]\n",
    "decision = (prediction >=0.5)\n",
    "accuracy = round((y_val == decision).mean(), 2)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Least Feature with Feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy_score</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms_per_room</td>\n",
       "      <td>0.83697</td>\n",
       "      <td>0.00303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_rooms</td>\n",
       "      <td>0.83672</td>\n",
       "      <td>0.00328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_bedrooms</td>\n",
       "      <td>0.83600</td>\n",
       "      <td>0.00400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>population_per_household</td>\n",
       "      <td>0.83576</td>\n",
       "      <td>0.00424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rooms_per_household</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.83309</td>\n",
       "      <td>0.00691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>households</td>\n",
       "      <td>0.83309</td>\n",
       "      <td>0.00691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>housing_median_age</td>\n",
       "      <td>0.83115</td>\n",
       "      <td>0.00885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.82897</td>\n",
       "      <td>0.01103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>population</td>\n",
       "      <td>0.82631</td>\n",
       "      <td>0.01369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ocean_proximity</td>\n",
       "      <td>0.81953</td>\n",
       "      <td>0.02047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>median_income</td>\n",
       "      <td>0.78658</td>\n",
       "      <td>0.05342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature  Accuracy_score  Difference\n",
       "0          bedrooms_per_room         0.83697     0.00303\n",
       "1                total_rooms         0.83672     0.00328\n",
       "2             total_bedrooms         0.83600     0.00400\n",
       "3   population_per_household         0.83576     0.00424\n",
       "4        rooms_per_household         0.83479     0.00521\n",
       "5                   latitude         0.83309     0.00691\n",
       "6                 households         0.83309     0.00691\n",
       "7         housing_median_age         0.83115     0.00885\n",
       "8                  longitude         0.82897     0.01103\n",
       "9                 population         0.82631     0.01369\n",
       "10           ocean_proximity         0.81953     0.02047\n",
       "11             median_income         0.78658     0.05342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_col = categorical_col + numerical_col\n",
    "\n",
    "feature = []\n",
    "global_acc = []\n",
    "diff = []\n",
    "for col in full_col:\n",
    "    new_col = [i for i in full_col if i != col]\n",
    "    X_train = dv.transform(train_df[new_col].to_dict(orient = 'records'))\n",
    "    X_val = dv.transform(val_df[new_col].to_dict(orient = 'records'))\n",
    "\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    prediction = model.predict_proba(X_val)[:, 1]\n",
    "    decision = (prediction >=0.5)\n",
    "    new_acc = round((y_val == decision).mean(), 5)\n",
    "    global_acc.append(new_acc)\n",
    "    feature.append(col)\n",
    "    diff.append(round((accuracy - new_acc), 5))\n",
    "\n",
    "out = pd.DataFrame({'Feature':feature, 'Accuracy_score': global_acc, 'Difference': diff})\n",
    "out.sort_values(by = ['Difference']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAta Preparation\n",
    "new_df = data.copy()\n",
    "\n",
    "train_df, test_df = train_test_split(new_df, test_size = 0.2, random_state = 42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#Transforming target variable\n",
    "y_train = np.log1p(train_df.pop('median_house_value'))\n",
    "y_test = np.log1p(test_df.pop('median_house_value'))\n",
    "y_val = np.log1p(val_df.pop('median_house_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorising data\n",
    "dv.fit(train_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "names = dv.get_feature_names()\n",
    "\n",
    "X_train = dv.transform(train_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "X_test = dv.transform(test_df[numerical_col + categorical_col].to_dict(orient = 'records'))\n",
    "X_val = dv.transform(val_df[numerical_col + categorical_col].to_dict(orient = 'records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    '''Returns root mean squared error'''\n",
    "    error = actual - predicted\n",
    "    rms = np.square(error)\n",
    "    rms = np.mean(rms)\n",
    "    return np.sqrt(rms)\n",
    "\n",
    "#Training Model with different alpha\n",
    "alpha_value = [0, 0.01, 0.1, 1, 10]\n",
    "errors = []\n",
    "for a in alpha_value:\n",
    "    model = Ridge(alpha=a, solver=\"sag\", random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_val)\n",
    "    error = round(rmse(y_val, prediction), 3)\n",
    "    errors.append(error)\n",
    "\n",
    "output = pd.DataFrame({'Alpha Value': alpha_value, 'Error': errors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Selecting model with the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.00\n",
       "1     0.01\n",
       "2     0.10\n",
       "3     1.00\n",
       "4    10.00\n",
       "Name: Alpha Value, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting Value with the lowest error\n",
    "output[output['Error'] == output['Error'].min()]['Alpha Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "Name: Alpha Value, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting Based on the smallest value\n",
    "output[output['Alpha Value'] == output['Alpha Value'].min()]['Alpha Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alpha is 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
